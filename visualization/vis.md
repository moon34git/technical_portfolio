# Visualization: λ¨λΈ ν•΄μ„ κ°€λ¥μ„± λ¶„μ„

λ³Έ λ””λ ‰ν† λ¦¬λ” νμΈνλ‹λ λ¨λΈμ μμΈ΅ κ³Όμ •μ„ μ‹κ°ν™”ν•κ³  ν•΄μ„ν•κΈ° μ„ν• Class Activation Map(CAM) λ¶„μ„ λ„κµ¬λ¥Ό μ κ³µν•©λ‹λ‹¤.

---

## π“ λ””λ ‰ν† λ¦¬ κµ¬μ΅°

```
visualization/
β”β”€β”€ cam.ipynb              # CAM μ‹κ°ν™” λ©”μΈ λ…ΈνΈλ¶
β”β”€β”€ configs.yaml           # μ‹κ°ν™” μ„¤μ • νμΌ
β”β”€β”€ vis.md                 # λ³Έ λ¬Έμ„
β””β”€β”€ cam_results/           # μ‹κ°ν™” κ²°κ³Ό μ €μ¥ λ””λ ‰ν† λ¦¬
    β””β”€β”€ integrated_comparison.png
```

---

## π― λ©μ 

νμΈνλ‹λ λ¨λΈμ΄ **μ–΄λ–¤ μμ—­**μ— μ§‘μ¤‘ν•μ—¬ μμΈ΅μ„ μν–‰ν•λ”μ§€ μ‹κ°μ μΌλ΅ λ¶„μ„ν•©λ‹λ‹¤:

1. **λ¨λΈ λΉ„κµ**: Adapter κΈ°λ° νμΈνλ‹ vs μ „μ²΄ λ¨λΈ νμΈνλ‹
2. **μμΈ΅ μ‹ λΆ°λ„ κ²€μ¦**: λ¨λΈμ΄ μ¬λ°”λ¥Έ λ³‘λ³€ μμ—­μ„ λ³΄κ³  μλ”μ§€ ν™•μΈ
3. **μ¤λ¥ λ¶„μ„**: μλ»λ μμΈ΅ μ‹ λ¨λΈμ μ£Όλ© μμ—­ λ¶„μ„

---

## π” μ‹κ°ν™” λ°©λ²•

### 1οΈβƒ£ XGradCAM (Adapter κΈ°λ° λ¨λΈ)

#### νΉμ§•
- Gradient κΈ°λ°μ CAM λ°©λ²•
- μ±„λ„λ³„ μ¤‘μ”λ„λ¥Ό κ°€μ¤‘ ν‰κ· ν•μ—¬ ν™μ„±ν™” λ§µ μƒμ„±
- **Adapter λ μ΄μ–΄**μ μ¶λ ¥μ— μ μ©

#### μ μ© λ€μƒ
- **Adapter κΈ°λ° νμΈνλ‹ λ¨λΈ**
- λ§μ§€λ§‰ Adapter λ μ΄μ–΄λ¥Ό νƒ€κ² λ μ΄μ–΄λ΅ μ„¤μ •
- κ²½λ‰ νμΈνλ‹μ—μ„ μ¶”κ°€λ λ μ΄μ–΄κ°€ μ–΄λ””λ¥Ό λ³΄λ”μ§€ λ¶„μ„

#### μ¥μ 
- νΉμ • λ μ΄μ–΄μ μν–¥λ ¥μ„ μ§μ ‘μ μΌλ΅ ν™•μΈ
- λ†’μ€ κ³µκ°„ ν•΄μƒλ„ μ μ§€
- μμΈ΅ ν΄λμ¤μ— λ€ν• κµ­μ†μ  μ¤‘μ” μμ—­ κ°•μ΅°

---

### 2οΈβƒ£ Attention Rollout (μ „μ²΄ λ¨λΈ νμΈνλ‹)

#### νΉμ§•
- Transformerμ Self-Attentionμ„ ν™μ©
- λ¨λ“  λ μ΄μ–΄μ Attentionμ„ κ³±ν•μ—¬ λ„μ (Rollout)
- **CLS ν† ν°**μ΄ μ΄λ―Έμ§€ ν¨μΉμ— μ–Όλ§λ‚ μ§‘μ¤‘ν•λ”μ§€ μΈ΅μ •

#### μ μ© λ€μƒ
- **μ „μ²΄ λ¨λΈ νμΈνλ‹ (Full Fine-Tuning)**
- MAE Encoderμ λ¨λ“  Transformer λΈ”λ΅μ—μ„ Attention μ¶”μ¶

#### μ¥μ 
- λ¨λΈμ μ „μ—­μ  μ£Όλ© ν¨ν„΄ νμ•…
- ViT κΈ°λ° λ¨λΈμ κ³ μ ν• νΉμ„± ν™μ©
- λ μ΄μ–΄ κ°„ μ •λ³΄ νλ¦„ μ¶”μ  κ°€λ¥

---

## π› οΈ μ£Όμ” κµ¬μ„± μ”μ†

### `cam.ipynb`

μ „μ²΄ μ‹κ°ν™” νμ΄ν”„λΌμΈμ„ ν¬ν•¨ν• Jupyter λ…ΈνΈλ¶

#### π“ μ£Όμ” μ„Ήμ…

**1. λ°μ΄ν„° μ¤€λΉ„**
- APTOS λ‹Ήλ‡¨λ§λ§‰λ³‘μ¦ λ°μ΄ν„°μ…‹ λ΅λ“
- Ground Truth λΌλ²¨ λ§¤ν•‘

**2. λ¨λΈ λ΅λ“**
```python
# μ‚¬μ „ ν•™μµλ MAE μΈμ½”λ”
mae_encoder = MaskedAutoencoderViT(...)

# Adapter κΈ°λ° νμΈνλ‹ λ¨λΈ
adapter_model = torch.load(adapter_model_path)

# μ „μ²΄ λ¨λΈ νμΈνλ‹ λ¨λΈ
direct_model = torch.load(direct_model_path)
```

**3. λνΌ ν΄λμ¤**
- `EncoderAdapterWrapper`: XGradCAMμ„ μ„ν• λ¨λΈ λν•‘
- `MAEEncoder`: Attention Rolloutμ„ μ„ν• μΈμ½”λ” λν•‘

**4. μ‹κ°ν™” ν•¨μ**
- `get_xgradcam_heatmap()`: XGradCAM ννΈλ§µ μƒμ„±
- `get_attention_rollout_heatmap()`: Attention Rollout ννΈλ§µ μƒμ„±
- `apply_heatmap_overlay()`: μ›λ³Έ μ΄λ―Έμ§€μ— ννΈλ§µ μ¤λ²„λ μ΄

**5. ν†µν•© λΉ„κµ**
- κ° μƒν”μ— λ€ν•΄ 3κ°€μ§€ λ·° μƒμ„±:
  1. **μ›λ³Έ μ΄λ―Έμ§€** (Ground Truth ν¬ν•¨)
  2. **Attention Rollout** (μ „μ²΄ νμΈνλ‹ μμΈ΅)
  3. **XGradCAM** (Adapter κΈ°λ° μμΈ΅)

---

### `configs.yaml`

μ‹κ°ν™”μ— ν•„μ”ν• λ¨λ“  μ„¤μ • μ •λ³΄

#### μ£Όμ” μ„¤μ •

```yaml
# λ°μ΄ν„°μ…‹ μ •λ³΄
DATASET: 'APTOSDataset'
IMG_DIR: "/path/"
CSV_DIR: "/path/label.csv"

# λ¨λΈ μ„¤μ •
IMG_SIZE: 224
PATCH_SIZE: 16
NUM_CLASSES: 2

# μ •κ·ν™” νλΌλ―Έν„°
MEAN: [0.4818, 0.2620, 0.0985]
STD: [0.2379, 0.1371, 0.0576]

# λ¨λΈ κ²½λ΅
MODEL_PATH: '/path/to/global_model.pt'
```

---

## π“ μ‹κ°ν™” κ²°κ³Ό ν•΄μ„

### κ²°κ³Ό μ΄λ―Έμ§€ κµ¬μ΅°

```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚   Original  β”‚  Attention Rollout   β”‚      XGradCAM       β”‚
β”‚   GT: 0/1   β”‚    Pred: 0/1 (Full)  β”‚  Pred: 0/1 (Adapter)β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚  μƒν” 1     β”‚   μ „μ²΄ FT μ‹κ°ν™”     β”‚  Adapter FT μ‹κ°ν™”  β”‚
β”‚  μƒν” 2     β”‚         ...          β”‚        ...          β”‚
β”‚    ...      β”‚         ...          β”‚        ...          β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

---

## π€ μ‚¬μ© λ°©λ²•

### 1. ν™κ²½ μ„¤μ •

```bash
pip install torch torchvision
pip install pytorch-grad-cam
pip install opencv-python matplotlib pyyaml
```

### 2. μ„¤μ • νμΌ μ¤€λΉ„

`configs.yaml`μ—μ„ λ‹¤μ κ²½λ΅λ“¤μ„ μ„¤μ •:
- λ°μ΄ν„°μ…‹ μ΄λ―Έμ§€ λ””λ ‰ν† λ¦¬
- CSV λΌλ²¨ νμΌ
- μ‚¬μ „ ν•™μµ λ¨λΈ κ²½λ΅
- Adapter λ¨λΈ κ²½λ΅
- Direct νμΈνλ‹ λ¨λΈ κ²½λ΅

### 3. λ…ΈνΈλ¶ μ‹¤ν–‰

```bash
jupyter notebook cam.ipynb
```

λλ” Jupyter Lab:

```bash
jupyter lab cam.ipynb
```

### 4. κ²°κ³Ό ν™•μΈ

`cam_results/integrated_comparison.png`μ—μ„ ν†µν•© λΉ„κµ κ²°κ³Ό ν™•μΈ

---

## π“ μ°Έκ³  λ¬Έν—

### CAM κ΄€λ ¨ λ…Όλ¬Έ

1. **CAM**: Zhou et al., "Learning Deep Features for Discriminative Localization" (CVPR 2016)
2. **GradCAM**: Selvaraju et al., "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization" (ICCV 2017)
3. **GradCAM++**: Chattopadhay et al., "Grad-CAM++: Generalized Gradient-Based Visual Explanations" (WACV 2018)
4. **Attention Rollout**: Abnar & Zuidema, "Quantifying Attention Flow in Transformers" (ACL 2020)

---

## π”— κ΄€λ ¨ λ¦¬μ†μ¤

- **PyTorch GradCAM Library**: https://github.com/jacobgil/pytorch-grad-cam
- **λ³Έ ν”„λ΅μ νΈ ν”„λ μ„μ›ν¬**: [../src/framework.md](../src/framework.md)

---